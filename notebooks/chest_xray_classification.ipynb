{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066da11d-9eb5-42d4-af4e-4685ee498f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chest X-Ray Classification using an Inception-like Neural Network\n",
    "\n",
    "## Step 1: Importing necessary libraries and setting up paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Setting image size and batch size\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "# Directory to the dataset (modify this path according to your setup)\n",
    "data_dir = \"chest_xray_dataset/train\"\n",
    "\n",
    "# Loading the dataset with a 20% validation split\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "\tdata_dir,\n",
    "\tvalidation_split=0.2,\n",
    "\tsubset=\"training\",\n",
    "\tseed=123,\n",
    "\timage_size=(img_height, img_width),\n",
    "\tbatch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "\tdata_dir,\n",
    "\tvalidation_split=0.2,\n",
    "\tsubset=\"validation\",\n",
    "\tseed=123,\n",
    "\timage_size=(img_height, img_width),\n",
    "\tbatch_size=batch_size)\n",
    "\n",
    "# Retrieve class names\n",
    "class_names = train_ds.class_names\n",
    "print(f\"Class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce08db-9c25-4e7d-906d-393d968cb1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Visualizing the dataset\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i+1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "# Save visualizations of some sample images\n",
    "plt.savefig(\"directory to save visualization!\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d63c40e-9647-464c-b3ec-127f6b1667cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3: Defining the Inception-like model\n",
    "\n",
    "# Normalizing the dataset for better performance\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Define an inception module\n",
    "def inception_module(input_tensor, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5, filters_pool_proj):\n",
    "    conv_1x1 = tf.keras.layers.Conv2D(filters_1x1, (1,1), padding=\"same\", activation=\"relu\")(input_tensor)\n",
    "    \n",
    "    conv_3x3 = tf.keras.layers.Conv2D(filters_3x3_reduce, (1,1), padding=\"same\", activation='relu')(input_tensor)\n",
    "    conv_3x3 = tf.keras.layers.Conv2D(filters_3x3, (3,3), padding=\"same\", activation=\"relu\")(conv_3x3)\n",
    "\n",
    "    conv_5x5 = tf.keras.layers.Conv2D(filters_5x5_reduce, (1,1), padding=\"same\", activation='relu')(input_tensor)\n",
    "    conv_5x5 = tf.keras.layers.Conv2D(filters_5x5, (5,5), padding=\"same\", activation=\"relu\")(conv_5x5)\n",
    "\n",
    "    pool_proj = tf.keras.layers.MaxPooling2D((3,3), strides=(1,1), padding=\"same\")(input_tensor)\n",
    "    pool_proj = tf.keras.layers.Conv2D(filters_pool_proj, (1,1), padding=\"same\", activation=\"relu\")(pool_proj)\n",
    "\n",
    "    output = tf.keras.layers.concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj])\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Build the Inception-like model\n",
    "def build_inception_like_model(input_shape=(img_height, img_width, 3)):\n",
    "    input_tensor = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(64, (7,7), strides=(2,2), padding=\"same\", activation=\"relu\")(input_tensor)\n",
    "    x = tf.keras.layers.MaxPooling2D((3,3),  strides=(2,2), padding=\"same\")(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(64, (1,1), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Conv2D(192, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding=\"same\")(x)\n",
    "\n",
    "    x = inception_module(x, filters_1x1=64, filters_3x3_reduce=96, filters_3x3=128, filters_5x5_reduce=16, filters_5x5=32, filters_pool_proj=32)\n",
    "    x = inception_module(x, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=192, filters_5x5_reduce=32, filters_5x5=96, filters_pool_proj=64)\n",
    "\n",
    "    x = tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding=\"same\")(x)\n",
    "\n",
    "    x = inception_module(x, filters_1x1=192, filters_3x3_reduce=96, filters_3x3=208, filters_5x5_reduce=16, filters_5x5=48, filters_pool_proj=64)\n",
    "    x = inception_module(x, filters_1x1=160, filters_3x3_reduce=112, filters_3x3=224, filters_5x5_reduce=24, filters_5x5=64, filters_pool_proj=64)\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    output_tensor = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the Inception-like model\n",
    "inception_like_model = build_inception_like_model(input_shape=(img_height, img_width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c3980c-7477-4dec-93fd-626323413eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: Compiling and summarizing the model\n",
    "\n",
    "# Compile the model\n",
    "inception_like_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5), loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "# Save the model summary to a text file\n",
    "def save_model_summary(model, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "save_model_summary(inception_like_model, 'chest_xray_model_summary.txt') # change the directory to save the model to your local folder\n",
    "\n",
    "# Display the model summary\n",
    "inception_like_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29066c23-3056-4247-8abb-45713e28e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 5: Training the model\n",
    "\n",
    "# EarlyStopping callback to prevent overfitting\n",
    "early_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=1,\n",
    "    mode=\"auto\",\n",
    "    restore_best_weights=True)\n",
    "\n",
    "# Train the model for 100 epochs (stopping early if overfitting starts)\n",
    "epochs = 100\n",
    "model_progress = inception_like_model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=[early_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c439d02-1c0b-40c2-b5f8-3ab3ca771000",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 6: Saving the trained model\n",
    "\n",
    "# Save the trained model\n",
    "inception_like_model.save(\"chest_xray_prediction_model.keras\") # you can modify the directory to save the model in your local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245df907-89fe-4499-9422-7772418c0ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 7: Visualizing training results\n",
    "\n",
    "# Retrieve accuracy and loss data from training history\n",
    "acc = model_progress.history['accuracy']\n",
    "val_accuracy = model_progress.history['val_accuracy']\n",
    "\n",
    "loss = model_progress.history['loss']\n",
    "val_loss = model_progress.history['val_loss']\n",
    "\n",
    "# Number of epochs the model was trained for\n",
    "epochs_trained = len(model_progress.history['loss'])\n",
    "epochs_range = range(epochs_trained)\n",
    "\n",
    "# Plot training and validation accuracy/loss\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label=\"Training Accuracy\")\n",
    "plt.plot(epochs_range, val_accuracy, label=\"Validation Accuracy\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label=\"Training Loss\")\n",
    "plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "\n",
    "# Save the training graph\n",
    "plt.savefig(\"directory to save the picture!\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
